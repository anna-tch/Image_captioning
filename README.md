---


---

<h1 id="image_captioning">Image_captioning</h1>
<p>1291 unique medical images x 5 captions:</p>
<ul>
<li><strong>Train dataset</strong> :<br>
5805 captions</li>
<li><strong>Test dataset</strong> :<br>
650 captions</li>
</ul>
<p>Last BLEU score achieved on the test dataset :<br>
BLEU-1: 0.896737<br>
BLEU-2: 0.835396<br>
BLEU-3: 0.790778<br>
BLEU-4: 0.728581</p>
<blockquote>
<p><em>Credits for the encode-decoder model to <a href="https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/image_captioning.ipynb">https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/image_captioning.ipynb</a> , data augmentation part (completed soon) is inspired from the paper - <a href="https://thesai.org/Downloads/Volume10No10/Paper_74-Data_Augmentation_to_Stabilize_Image_Caption_Generation_Models.pdf">https://thesai.org/Downloads/Volume10No10/Paper_74-Data_Augmentation_to_Stabilize_Image_Caption_Generation_Models.pdf</a></em></p>
</blockquote>

